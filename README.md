# ML-SAINT
Reposit√≥rio oficial do projeto comparando o modelo **SAINT (Self-Attention Transformer)** com modelos tradicionais (LightGBM, XGBoost, CatBoost) e ferramentas AutoML (AutoGluon, auto-sklearn) em 30 datasets tabulares do OpenML-CC18.

# SAINT vs Gradient Boosting & AutoML for Tabular Data

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Reposit√≥rio oficial do projeto comparando o modelo **SAINT (Self-Attention Transformer)** com modelos tradicionais (LightGBM, XGBoost, CatBoost) e ferramentas AutoML (AutoGluon, auto-sklearn) em 30 datasets tabulares do OpenML-CC18.

## üîç Contexto
Trabalho final da disciplina de Aprendizagem de M√°quina (2025) com objetivo de:
- Implementar e avaliar o SAINT - modelo Transformer para dados tabulares
- Comparar com benchmarks de Gradient Boosting e AutoML
- Aplicar protocolo estat√≠stico rigoroso (teste de Dem≈°ar)

## üöÄ Principais Resultados
- ‚úÖ **AutoGluon** obteve melhor performance geral (acur√°cia)
- ‚ö° **LightGBM** foi o mais eficiente (tempo de execu√ß√£o)
- üß† **SAINT** mostrou potencial competitivo, especialmente em AUC-OVO
- üìä CatBoost teve melhor generaliza√ß√£o (menor overfitting)

## üìä M√©tricas Analisadas
- Acur√°cia (Accuracy)
- AUC One-vs-One (AUC-OVO)
- Entropia Cruzada (Cross-Entropy)
- Tempo de execu√ß√£o

## üõ†Ô∏è Como Reproduzir
1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/seuuser/SAINT-Tabular-Data-Classification.git
2. Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt   
3. Execute os scripts (veja detalhes na documenta√ß√£o)

## üìÑ Documenta√ß√£o Completa
- [Relat√≥rio T√©cnico](/docs/relatorio_final.pdf)
- [Apresenta√ß√£o](/docs/apresentacao.pdf)
