# SAINT vs Gradient Boosting & AutoML for Tabular Data

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

RepositÃ³rio oficial do projeto comparando o modelo **SAINT (Self-Attention Transformer)** com modelos tradicionais (LightGBM, XGBoost, CatBoost) e ferramentas AutoML (AutoGluon, auto-sklearn) em 30 datasets tabulares do OpenML-CC18.

## ğŸ” Contexto
Trabalho final da disciplina de Aprendizagem de MÃ¡quina (2025) com objetivo de:
- Implementar e avaliar o SAINT - modelo Transformer para dados tabulares
- Comparar com benchmarks de Gradient Boosting e AutoML
- Aplicar protocolo estatÃ­stico rigoroso (teste de DemÅ¡ar)

## ğŸš€ Principais Resultados
- âœ… **AutoGluon** obteve melhor performance geral (acurÃ¡cia)
- âš¡ **LightGBM** foi o mais eficiente (tempo de execuÃ§Ã£o)
- ğŸ§  **SAINT** mostrou potencial competitivo, especialmente em AUC-OVO
- ğŸ“Š CatBoost teve melhor generalizaÃ§Ã£o (menor overfitting)

## ğŸ“Š MÃ©tricas Analisadas
- AcurÃ¡cia (Accuracy)
- AUC One-vs-One (AUC-OVO)
- Entropia Cruzada (Cross-Entropy)
- Tempo de execuÃ§Ã£o

## ğŸ› ï¸ Como Reproduzir
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/brenoman/ML-SAINT.git
2. Instale as dependÃªncias:
    ```bash
    pip install -r requirements.txt   
3. Execute os scripts (veja detalhes na documentaÃ§Ã£o)

## ğŸ“„ DocumentaÃ§Ã£o Completa
- [RelatÃ³rio TÃ©cnico](/docs/relatorio_final.pdf)
- [ApresentaÃ§Ã£o](/docs/apresentacao.pdf)
